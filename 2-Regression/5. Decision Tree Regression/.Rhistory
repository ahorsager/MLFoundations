colnames(Games) <- Seasons
rownames(Games) <- Players
#Minutes Played
KobeBryant_MP <- c(3277,3140,3192,2960,2835,2779,2232,3013,177,1207)
JoeJohnson_MP <- c(3340,2359,3343,3124,2886,2554,2127,2642,2575,2791)
LeBronJames_MP <- c(3361,3190,3027,3054,2966,3063,2326,2877,2902,2493)
CarmeloAnthony_MP <- c(2941,2486,2806,2277,2634,2751,1876,2482,2982,1428)
DwightHoward_MP <- c(3021,3023,3088,2821,2843,2935,2070,2722,2396,1223)
ChrisBosh_MP <- c(2751,2658,2425,2928,2526,2795,2007,2454,2531,1556)
ChrisPaul_MP <- c(2808,2353,3006,3002,1712,2880,2181,2335,2171,2857)
KevinDurant_MP <- c(1255,1255,2768,2885,3239,3038,2546,3119,3122,913)
DerrickRose_MP <- c(1168,1168,1168,3000,2871,3026,1375,0,311,1530)
DwayneWade_MP <- c(2892,1931,1954,3048,2792,2823,1625,2391,1775,1971)
#Matrix
MinutesPlayed <- rbind(KobeBryant_MP, JoeJohnson_MP, LeBronJames_MP, CarmeloAnthony_MP, DwightHoward_MP, ChrisBosh_MP, ChrisPaul_MP, KevinDurant_MP, DerrickRose_MP, DwayneWade_MP)
rm(KobeBryant_MP, JoeJohnson_MP, CarmeloAnthony_MP, DwightHoward_MP, ChrisBosh_MP, LeBronJames_MP, ChrisPaul_MP, DerrickRose_MP, DwayneWade_MP, KevinDurant_MP)
colnames(MinutesPlayed) <- Seasons
rownames(MinutesPlayed) <- Players
#Field Goals
KobeBryant_FG <- c(978,813,775,800,716,740,574,738,31,266)
JoeJohnson_FG <- c(632,536,647,620,635,514,423,445,462,446)
LeBronJames_FG <- c(875,772,794,789,768,758,621,765,767,624)
CarmeloAnthony_FG <- c(756,691,728,535,688,684,441,669,743,358)
DwightHoward_FG <- c(468,526,583,560,510,619,416,470,473,251)
ChrisBosh_FG <- c(549,543,507,615,600,524,393,485,492,343)
ChrisPaul_FG <- c(407,381,630,631,314,430,425,412,406,568)
KevinDurant_FG <- c(306,306,587,661,794,711,643,731,849,238)
DerrickRose_FG <- c(208,208,208,574,672,711,302,0,58,338)
DwayneWade_FG <- c(699,472,439,854,719,692,416,569,415,509)
#Matrix
FieldGoals <- rbind(KobeBryant_FG, JoeJohnson_FG, LeBronJames_FG, CarmeloAnthony_FG, DwightHoward_FG, ChrisBosh_FG, ChrisPaul_FG, KevinDurant_FG, DerrickRose_FG, DwayneWade_FG)
rm(KobeBryant_FG, JoeJohnson_FG, LeBronJames_FG, CarmeloAnthony_FG, DwightHoward_FG, ChrisBosh_FG, ChrisPaul_FG, KevinDurant_FG, DerrickRose_FG, DwayneWade_FG)
colnames(FieldGoals) <- Seasons
rownames(FieldGoals) <- Players
#Field Goal Attempts
KobeBryant_FGA <- c(2173,1757,1690,1712,1569,1639,1336,1595,73,713)
JoeJohnson_FGA <- c(1395,1139,1497,1420,1386,1161,931,1052,1018,1025)
LeBronJames_FGA <- c(1823,1621,1642,1613,1528,1485,1169,1354,1353,1279)
CarmeloAnthony_FGA <- c(1572,1453,1481,1207,1502,1503,1025,1489,1643,806)
DwightHoward_FGA <- c(881,873,974,979,834,1044,726,813,800,423)
ChrisBosh_FGA <- c(1087,1094,1027,1263,1158,1056,807,907,953,745)
ChrisPaul_FGA <- c(947,871,1291,1255,637,928,890,856,870,1170)
KevinDurant_FGA <- c(647,647,1366,1390,1668,1538,1297,1433,1688,467)
DerrickRose_FGA <- c(436,436,436,1208,1373,1597,695,0,164,835)
DwayneWade_FGA <- c(1413,962,937,1739,1511,1384,837,1093,761,1084)
#Matrix
FieldGoalAttempts <- rbind(KobeBryant_FGA, JoeJohnson_FGA, LeBronJames_FGA, CarmeloAnthony_FGA, DwightHoward_FGA, ChrisBosh_FGA, ChrisPaul_FGA, KevinDurant_FGA, DerrickRose_FGA, DwayneWade_FGA)
rm(KobeBryant_FGA, JoeJohnson_FGA, LeBronJames_FGA, CarmeloAnthony_FGA, DwightHoward_FGA, ChrisBosh_FGA, ChrisPaul_FGA, KevinDurant_FGA, DerrickRose_FGA, DwayneWade_FGA)
colnames(FieldGoalAttempts) <- Seasons
rownames(FieldGoalAttempts) <- Players
#Points
KobeBryant_PTS <- c(2832,2430,2323,2201,1970,2078,1616,2133,83,782)
JoeJohnson_PTS <- c(1653,1426,1779,1688,1619,1312,1129,1170,1245,1154)
LeBronJames_PTS <- c(2478,2132,2250,2304,2258,2111,1683,2036,2089,1743)
CarmeloAnthony_PTS <- c(2122,1881,1978,1504,1943,1970,1245,1920,2112,966)
DwightHoward_PTS <- c(1292,1443,1695,1624,1503,1784,1113,1296,1297,646)
ChrisBosh_PTS <- c(1572,1561,1496,1746,1678,1438,1025,1232,1281,928)
ChrisPaul_PTS <- c(1258,1104,1684,1781,841,1268,1189,1186,1185,1564)
KevinDurant_PTS <- c(903,903,1624,1871,2472,2161,1850,2280,2593,686)
DerrickRose_PTS <- c(597,597,597,1361,1619,2026,852,0,159,904)
DwayneWade_PTS <- c(2040,1397,1254,2386,2045,1941,1082,1463,1028,1331)
#Matrix
Points <- rbind(KobeBryant_PTS, JoeJohnson_PTS, LeBronJames_PTS, CarmeloAnthony_PTS, DwightHoward_PTS, ChrisBosh_PTS, ChrisPaul_PTS, KevinDurant_PTS, DerrickRose_PTS, DwayneWade_PTS)
rm(KobeBryant_PTS, JoeJohnson_PTS, LeBronJames_PTS, CarmeloAnthony_PTS, DwightHoward_PTS, ChrisBosh_PTS, ChrisPaul_PTS, KevinDurant_PTS, DerrickRose_PTS, DwayneWade_PTS)
colnames(Points) <- Seasons
rownames(Points) <- Players
Salary
?matrix
my.data <- 1:20
my.data
A <- matrix(my.data, 4, 5)
A
A <- matrix(my.data, 4, 5, byrow=T)
A
A[2,5]
library("caTools", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
# Importing the data set
DataSet = read.csv('SalaryData.csv')
# Split data into training and test
set.seed(123)
Split = sample.split(DataSet$Salary, SplitRatio = 2/3)
TrainingSet = subset(DataSet, Split == TRUE)
TestSet = subset(DataSet, Split == FALSE)
# Fitting linear regression to the data set
regressor = lm(formula = Salary ~ YearsExperience,
data = TrainingSet)
summary(regressor) # Summary of lm fit results
# Predict test set results
TestPredict = predict(regressor, newdata = TestSet)
# Data visualization of Training Set
ggplot() +
geom_point(aes(x = TrainingSet$YearsExperience, y = TrainingSet$Salary),
color = 'red') +
geom_line(aes(x = TrainingSet$YearsExperience, y = predict(regressor, newdata = TrainingSet)),
color = 'blue') +
ggtitle('Salary vs. Experience (Training Set)') +
xlab('Years of Experience') +
ylab('Salary')
#Data visualization of test set
ggplot() +
geom_point(aes(x = TestSet$YearsExperience, y = TestSet$Salary),
color = 'red') +
geom_line(aes(x = TrainingSet$YearsExperience, y = predict(regressor, newdata = TrainingSet)),
color = 'blue') +
ggtitle('Salary vs. Experience (Test Set)') +
xlab('Years of Experience') +
ylab('Salary')
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
# Importing the data set
DataSet = read.csv('SalaryData.csv')
# Split data into training and test
set.seed(123)
Split = sample.split(DataSet$Salary, SplitRatio = 2/3)
TrainingSet = subset(DataSet, Split == TRUE)
TestSet = subset(DataSet, Split == FALSE)
# Fitting linear regression to the data set
regressor = lm(formula = Salary ~ YearsExperience,
data = TrainingSet)
summary(regressor) # Summary of lm fit results
# Predict test set results
TestPredict = predict(regressor, newdata = TestSet)
# Data visualization of Training Set
ggplot() +
geom_point(aes(x = TrainingSet$YearsExperience, y = TrainingSet$Salary),
color = 'red') +
geom_line(aes(x = TrainingSet$YearsExperience, y = predict(regressor, newdata = TrainingSet)),
color = 'blue') +
ggtitle('Salary vs. Experience (Training Set)') +
xlab('Years of Experience') +
ylab('Salary')
#Data visualization of test set
ggplot() +
geom_point(aes(x = TestSet$YearsExperience, y = TestSet$Salary),
color = 'red') +
geom_line(aes(x = TrainingSet$YearsExperience, y = predict(regressor, newdata = TrainingSet)),
color = 'blue') +
ggtitle('Salary vs. Experience (Test Set)') +
xlab('Years of Experience') +
ylab('Salary')
# Simple linear regression model
# Importing the data set
setwd("/Users/horsager/Dropbox/projects/analytics/MLTraining/2-Regression/Simple Linear Regression")
DataSet = read.csv('SalaryData.csv')
# Split data into training and test
set.seed(123)
Split = sample.split(DataSet$Salary, SplitRatio = 2/3)
TrainingSet = subset(DataSet, Split == TRUE)
TestSet = subset(DataSet, Split == FALSE)
# Fitting linear regression to the data set
regressor = lm(formula = Salary ~ YearsExperience,
data = TrainingSet)
summary(regressor) # Summary of lm fit results
# Predict test set results
TestPredict = predict(regressor, newdata = TestSet)
# Data visualization of Training Set
ggplot() +
geom_point(aes(x = TrainingSet$YearsExperience, y = TrainingSet$Salary),
color = 'red') +
geom_line(aes(x = TrainingSet$YearsExperience, y = predict(regressor, newdata = TrainingSet)),
color = 'blue') +
ggtitle('Salary vs. Experience (Training Set)') +
xlab('Years of Experience') +
ylab('Salary')
#Data visualization of test set
ggplot() +
geom_point(aes(x = TestSet$YearsExperience, y = TestSet$Salary),
color = 'red') +
geom_line(aes(x = TrainingSet$YearsExperience, y = predict(regressor, newdata = TrainingSet)),
color = 'blue') +
ggtitle('Salary vs. Experience (Test Set)') +
xlab('Years of Experience') +
ylab('Salary')
setwd("/Users/horsager/Dropbox/projects/analytics/MLTraining/2-Regression/Multiple Linear Regression")
DataSet = read.csv('50Startups.csv')
View(DataSet)
#Convert categorical data into factors
DataSet$State = factor(DataSet$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1, 2, 3))
# Split data into training and test sets
set.seed(123)
Split = sample.split(DataSet$Profit, SplitRatio = 0.8)
TrainingSet = subset(DataSet, Split == TRUE)
TestSet = subset(DataSet, Split == FALSE)
View(TestSet)
View(TrainingSet)
regressor = lm(formula = Profit ~ .,
data = TrainingSet)
summary(regressor) # Summary of lm fit results
#### MODEL ####
# Fitting linear regression to the data set
regressor = lm(formula = Profit ~ ., # Profit is a linear combination of all independent variables
data = TrainingSet)
summary(regressor) # Summary of lm fit results
TestPredict = predict(regressor, newdata = TestSet)
regressor1 = lm(formula = Profit ~ R.D.Spend + Adminstration + Marketing.Spend,
data = DataSet)
summary(regressor1)
regressor = lm(formula = Profit ~ R.D.Spend + Adminstration + Marketing.Spend,
data = DataSet)
summary(regressor)
setwd("/Users/horsager/Dropbox/projects/analytics/MLTraining/2-Regression/Multiple Linear Regression")
DataSet = read.csv('50Startups.csv')
#Convert categorical data into factors
DataSet$State = factor(DataSet$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1, 2, 3))
set.seed(123)
Split = sample.split(DataSet$Profit, SplitRatio = 0.8)
TrainingSet = subset(DataSet, Split == TRUE)
TestSet = subset(DataSet, Split == FALSE)
regressor = lm(formula = Profit ~ ., # Profit a linear combination of all ind vars
data = TrainingSet)
summary(regressor) # Summary of lm fit results
regressor = lm(formula = Profit ~ R.D.Spend + Adminstration + Marketing.Spend + State,
data = DataSet)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Adminstration + Marketing.Spend,
data = DataSet)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Marketing.Spend,
data = DataSet)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Adminstration + Marketing.Spend,
data = DataSet)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Adminstration + Marketing.Spend,
data = DataSet)
summary(regressor)
setwd("/Users/horsager/Dropbox/projects/analytics/MLTraining/2-Regression/Multiple Linear Regression")
DataSet = read.csv('50Startups.csv')
#Convert categorical data into factors
DataSet$State = factor(DataSet$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1, 2, 3))
set.seed(123)
Split = sample.split(DataSet$Profit, SplitRatio = 0.8)
TrainingSet = subset(DataSet, Split == TRUE)
TestSet = subset(DataSet, Split == FALSE)
regressor = lm(formula = Profit ~ ., # Profit a linear combination of all ind vars
data = TrainingSet)
summary(regressor) # Summary of lm fit results
regressor = lm(formula = Profit ~ R.D.Spend + Adminstration + Marketing.Spend + State,
data = DataSet)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Adminstration + Marketing.Spend,
data = DataSet)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Marketing.Spend,
data = DataSet)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Adminstration + Marketing.Spend,
data = DataSet)
summary(regressor)
setwd("/Users/horsager/Dropbox/projects/analytics/MLTraining/2-Regression/Multiple Linear Regression")
DataSet = read.csv('50Startups.csv')
#Convert categorical data into factors
DataSet$State = factor(DataSet$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1, 2, 3))
set.seed(123)
Split = sample.split(DataSet$Profit, SplitRatio = 0.8)
TrainingSet = subset(DataSet, Split == TRUE)
TestSet = subset(DataSet, Split == FALSE)
regressor = lm(formula = Profit ~ ., # Profit a linear combination of all ind vars
data = TrainingSet)
summary(regressor) # Summary of lm fit results
regressor = lm(formula = Profit ~ R.D.Spend + Adminstration + Marketing.Spend + State,
data = DataSet)
# Use Backward Elimination to optimize model
regressor = lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend + State,
data = DataSet)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend,
data = DataSet)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend + Marketing.Spend,
data = DataSet)
summary(regressor)
regressor = lm(formula = Profit ~ R.D.Spend,
data = DataSet)
summary(regressor)
backwardElimination <- function(x, sl) {
numVars = length(x)
for (i in c(1:numVars)){
regressor = lm(formula = Profit ~ ., data = x)
maxVar = max(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"])
if (maxVar > sl){
j = which(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"] == maxVar)
x = x[, -j]
}
numVars = numVars - 1
}
return(summary(regressor))
}
SL = 0.05
dataset = dataset[, c(1,2,3,4,5)]
backwardElimination(training_set, SL)
backwardElimination <- function(x, sl) {
numVars = length(x)
for (i in c(1:numVars)){
regressor = lm(formula = Profit ~ ., data = x)
maxVar = max(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"])
if (maxVar > sl){
j = which(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"] == maxVar)
x = x[, -j]
}
numVars = numVars - 1
}
return(summary(regressor))
}
SL = 0.05
DataSet = DataSet[, c(1,2,3,4,5)]
backwardElimination(TrainingSet, SL)
BackwardElimination <- function(x, sl) {
numVars = length(x)
for (i in c(1:numVars)){
regressor = lm(formula = Profit ~ ., data = x)
maxVar = max(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"])
if (maxVar > sl){
j = which(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"] == maxVar)
x = x[, -j]
}
numVars = numVars - 1
}
return(summary(regressor))
}
SL = 0.05
DataSet = DataSet[, c(1,2,3,4,5)]
BackwardElimination(TrainingSet, SL)
BackwardElimination <- function(x, sl) {
numVars = length(x)
for (i in c(1:numVars)){
regressor = lm(formula = Profit ~ ., data = x)
maxVar = max(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"])
if (maxVar > sl){
j = which(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"] == maxVar)
x = x[, -j]
}
numVars = numVars - 1
}
return(summary(regressor))
}
SL = 0.05
DataSet = DataSet[, c(1,2,3,4,5)]
BackwardElimination(TrainingSet, SL)
setwd("/Users/horsager/Dropbox/projects/analytics/MLTraining/2-Regression/Polynomial Regression")
DataSet = read.csv('PositionSalaries.csv')
View(DataSet)
DataSet = DataSet[:,2:3]
DataSet = DataSet[2:3]
DataSet$Level2 = DataSet$Level^2
DataSet$Level2 = DataSet$Level^2
DataSet$Level3 = DataSet$Level^3
regressor = lm(formula = Salary ~ .,
data = DataSet,
)
summary(regressor) # Summary of lm fit results
ggplot() +
geom_point(aes(x = DataSet$Level, y = DataSet$Salary),
color = 'red') +
geom_line(aes(x = DataSet$Level, y = predict(regressor, newdata = DataSet)),
color = 'blue') +
ggtitle('Salary vs. Level') +
xlab('Level') +
ylab('Salary')
DataSet$Level2 = DataSet$Level^2
#DataSet$Level3 = DataSet$Level^3
regressor = lm(formula = Salary ~ .,
data = DataSet,
)
summary(regressor) # Summary of lm fit results
ggplot() +
geom_point(aes(x = DataSet$Level, y = DataSet$Salary),
color = 'red') +
geom_line(aes(x = DataSet$Level, y = predict(regressor, newdata = DataSet)),
color = 'blue') +
ggtitle('Salary vs. Level') +
xlab('Level') +
ylab('Salary')
DataSet$Level2 = DataSet$Level^2
DataSet$Level3 = DataSet$Level^3
DataSet$Level4 = DataSet$Level^4
regressor = lm(formula = Salary ~ .,
data = DataSet,
)
summary(regressor) # Summary of lm fit results
ggplot() +
geom_point(aes(x = DataSet$Level, y = DataSet$Salary),
color = 'red') +
geom_line(aes(x = DataSet$Level, y = predict(regressor, newdata = DataSet)),
color = 'blue') +
ggtitle('Salary vs. Level') +
xlab('Level') +
ylab('Salary')
DataSet$Level2 = DataSet$Level^2
DataSet$Level3 = DataSet$Level^3
DataSet$Level4 = DataSet$Level^4
DataSet$Level5 = DataSet$Level^5
regressor = lm(formula = Salary ~ .,
data = DataSet,
)
summary(regressor) # Summary of lm fit results
ggplot() +
geom_point(aes(x = DataSet$Level, y = DataSet$Salary),
color = 'red') +
geom_line(aes(x = DataSet$Level, y = predict(regressor, newdata = DataSet)),
color = 'blue') +
ggtitle('Salary vs. Level') +
xlab('Level') +
ylab('Salary')
DataSet$Level2 = DataSet$Level^2
DataSet$Level3 = DataSet$Level^3
DataSet$Level4 = DataSet$Level^4
regressor = lm(formula = Salary ~ .,
data = DataSet,
)
summary(regressor) # Summary of lm fit results
ggplot() +
geom_point(aes(x = DataSet$Level, y = DataSet$Salary),
color = 'red') +
geom_line(aes(x = DataSet$Level, y = predict(regressor, newdata = DataSet)),
color = 'blue') +
ggtitle('Salary vs. Level') +
xlab('Level') +
ylab('Salary')
PredVal = predict(regressor, newdata = data.frame(Level = 6.5))
setwd("/Users/horsager/Dropbox/projects/analytics/MLTraining/2-Regression/Polynomial Regression")
DataSet = read.csv('PositionSalaries.csv')
DataSet = DataSet[2:3]
DataSet$Level2 = DataSet$Level^2
DataSet$Level3 = DataSet$Level^3
DataSet$Level4 = DataSet$Level^4
regressor = lm(formula = Salary ~ .,
data = DataSet)
summary(regressor) # Summary of lm fit results
PredVal = predict(regressor, newdata = data.frame(Level = 6.5))
Stuff = predict(regressor, newdata = data.frame(Level = 6.5))
regressor
newdata
newdata = data.frame(Level = 6.5)
newdata
predict(regressor, newdata = data.frame(Level = 6.5))
DataSet$Level
PredVal = predict(regressor, newdata = data.frame(Level = 6.5,
Level2 = 6.5^2,
Level3 = 6.5^3,
Level4 = 6.5^4))
PredVal
ggplot() +
geom_point(aes(x = DataSet$Level, y = DataSet$Salary),
color = 'red') +
geom_line(aes(x = DataSet$Level, y = predict(regressor, newdata = DataSet)),
color = 'blue') +
ggtitle('Salary vs. Level') +
xlab('Level') +
ylab('Salary')
SmoothX = seq(min(DataSet$Level), max(DataSet$Level), 0.1)
ggplot() +
geom_point(aes(x = DataSet$Level, y = DataSet$Salary),
color = 'red') +
geom_line(aes(x = SmoothX, y = predict(regressor, newdata = DataSet)),
color = 'blue') +
ggtitle('Salary vs. Level') +
xlab('Level') +
ylab('Salary')
SmoothX = seq(min(DataSet$Level), max(DataSet$Level), 0.1)
ggplot() +
geom_point(aes(x = DataSet$Level, y = DataSet$Salary),
color = 'red') +
geom_line(aes(x = SmoothX, y = predict(regressor, newdata = data.frame(Level = SmoothX))),
color = 'blue') +
ggtitle('Salary vs. Level') +
xlab('Level') +
ylab('Salary')
ggplot() +
geom_point(aes(x = DataSet$Level, y = DataSet$Salary),
color = 'red') +
geom_line(aes(x = DataSet$Level, y = predict(regressor, newdata = DataSet)),
color = 'blue') +
ggtitle('Salary vs. Level') +
xlab('Level') +
ylab('Salary')
install.packages(e1071)
install.packages('e1071')
library("e1071", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
setwd("/Users/horsager/Dropbox/projects/analytics/MLTraining/2-Regression/Support Vector Regression")
DataSet = read.csv('PositionSalaries.csv')
DataSet = DataSet[2:3]
regressor = svm(formula = Salary ~ .,
data = DataSet,
type = 'eps-regression')
summary(regressor) # Summary of lm fit results
PredVal = predict(regressor, newdata = data.frame(Level = 6.5))
PredVal
ggplot() +
geom_point(aes(x = DataSet$Level, y = DataSet$Salary),
color = 'red') +
geom_line(aes(x = DataSet$Level, y = predict(regressor, newdata = DataSet)),
color = 'blue') +
ggtitle('Salary vs. Level') +
xlab('Level') +
ylab('Salary')
setwd("/Users/horsager/Dropbox/projects/analytics/MLTraining/2-Regression/...
Support Vector Regression")
DataSet = read.csv('PositionSalaries.csv')
DataSet = DataSet[2:3]
setwd("/Users/horsager/Dropbox/projects/analytics/MLFoundations/2-Regression/Decision Tree Regression")
DataSet = read.csv('PositionSalaries.csv')
DataSet = DataSet[2:3]
View(DataSet)
library("rpart", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
